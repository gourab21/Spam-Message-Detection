{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\", encoding=\"cp1252\")  # Common on Windows\n",
    "data = data.rename(columns={\"v1\": \"category\", \"v2\": \"message\"})\n",
    "data['Spam']=data['category'].apply(lambda x:1 if x=='spam' else 0)\n",
    "X_train,X_test,y_train,y_test=train_test_split(data.message,data.Spam,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails=[\n",
    "    'Sounds great! Are you home now?',\n",
    "    'Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8982 - loss: 0.2957 - val_accuracy: 0.9839 - val_loss: 0.0550\n",
      "Epoch 2/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9883 - loss: 0.0458 - val_accuracy: 0.9874 - val_loss: 0.0424\n",
      "Epoch 3/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.0214 - val_accuracy: 0.9883 - val_loss: 0.0416\n",
      "Epoch 4/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0111 - val_accuracy: 0.9910 - val_loss: 0.0399\n",
      "Epoch 5/5\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 0.9812 - val_loss: 0.0458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "Message: Congratulations! You've won a free iPhone. Click here to claim now!\n",
      "Prediction: Spam (Score: 0.9578)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Parameters\n",
    "max_words = 5000  # Vocabulary size\n",
    "max_len = 100  # Max sequence length\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['message'])\n",
    "X = tokenizer.texts_to_sequences(data['message'])\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "\n",
    "# Convert labels to binary\n",
    "y = (data['category'] == 'spam').astype(int)\n",
    "\n",
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_message(model, tokenizer, message, max_len=100):\n",
    "    # Preprocess the message\n",
    "    sequence = tokenizer.texts_to_sequences([message])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "    # Interpret the result\n",
    "    return \"Spam\" if prediction > 0.5 else \"Not Spam\", prediction\n",
    "\n",
    "# Example message\n",
    "message = \"Congratulations! You've won a free iPhone. Click here to claim now!\"\n",
    "label, score = predict_message(model, tokenizer, message)\n",
    "\n",
    "print(f\"Message: {message}\")\n",
    "print(f\"Prediction: {label} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Embedding(max_words, 128, input_length=max_len),\n",
    "#     SpatialDropout1D(0.2),\n",
    "#     tf.keras.layers.Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X, y, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Save the entire model in the recommended Keras format\n",
    "# model.save(\"spam_classifier_lstm.keras\")\n",
    "\n",
    "# # Optionally, save the tokenizer as well\n",
    "# import pickle\n",
    "# with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
